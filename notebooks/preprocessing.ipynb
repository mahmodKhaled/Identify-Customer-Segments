{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Identify Customer Segments\n",
    "\n",
    "In this project, I will apply unsupervised learning techniques to identify segments of the population that form the core customer base for a mail-order sales company in Germany. These segments can then be used to direct marketing campaigns towards audiences that will have the highest expected rate of returns. The data that I will use has been provided by a partners at Bertelsmann Arvato Analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries here; add more as necessary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "# magic word for producing visualizations in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1097591243.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    There are four files associated with this project (not including this one):\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "### Step 0: Load the Data\n",
    "\n",
    "There are four files associated with this project (not including this one):\n",
    "\n",
    "- `Udacity_AZDIAS_Subset.csv`: Demographics data for the general population of Germany; 891211 persons (rows) x 85 features (columns).\n",
    "- `Udacity_CUSTOMERS_Subset.csv`: Demographics data for customers of a mail-order company; 191652 persons (rows) x 85 features (columns).\n",
    "- `Data_Dictionary.md`: Detailed information file about the features in the provided datasets.\n",
    "- `AZDIAS_Feature_Summary.csv`: Summary of feature attributes for demographics data; 85 features (rows) x 4 columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Load in the general demographics data.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m azdias \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mUdacity_AZDIAS_Subset.csv\u001b[39m\u001b[39m\"\u001b[39m,delimiter\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Load in the feature summary file.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m feat_info \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mAZDIAS_Feature_Summary.csv\u001b[39m\u001b[39m\"\u001b[39m,delimiter\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Load in the general demographics data.\n",
    "azdias = pd.read_csv(\"Udacity_AZDIAS_Subset.csv\",delimiter=\";\")\n",
    "\n",
    "# Load in the feature summary file.\n",
    "feat_info = pd.read_csv(\"AZDIAS_Feature_Summary.csv\",delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'azdias' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Check the structure of the data after it's loaded\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe general demographic data shape is \u001b[39m\u001b[39m\"\u001b[39m , azdias\u001b[39m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'azdias' is not defined"
     ]
    }
   ],
   "source": [
    "# Check the structure of the data after it's loaded\n",
    "print(\"The general demographic data shape is \" , azdias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'azdias' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m azdias\u001b[39m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'azdias' is not defined"
     ]
    }
   ],
   "source": [
    "azdias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'azdias' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m azdias\u001b[39m.\u001b[39mtail()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'azdias' is not defined"
     ]
    }
   ],
   "source": [
    "azdias.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'azdias' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m azdias\u001b[39m.\u001b[39mdescribe()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'azdias' is not defined"
     ]
    }
   ],
   "source": [
    "azdias.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'azdias' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m azdias\u001b[39m.\u001b[39minfo()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'azdias' is not defined"
     ]
    }
   ],
   "source": [
    "azdias.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feat_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Check the structure of the data after it's loaded\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe feature summary data shape is \u001b[39m\u001b[39m\"\u001b[39m , feat_info\u001b[39m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feat_info' is not defined"
     ]
    }
   ],
   "source": [
    "# Check the structure of the data after it's loaded\n",
    "print(\"The feature summary data shape is \" , feat_info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feat_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m feat_info\u001b[39m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feat_info' is not defined"
     ]
    }
   ],
   "source": [
    "feat_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feat_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m feat_info\u001b[39m.\u001b[39mtail()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feat_info' is not defined"
     ]
    }
   ],
   "source": [
    "feat_info.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feat_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m feat_info\u001b[39m.\u001b[39mdescribe()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feat_info' is not defined"
     ]
    }
   ],
   "source": [
    "feat_info.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feat_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m feat_info\u001b[39m.\u001b[39minfo()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feat_info' is not defined"
     ]
    }
   ],
   "source": [
    "feat_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1864957165.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[13], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    The feature summary file contains a summary of properties for each demographics data column. I will use this file to help me make cleaning decisions during this stage of the project. First of all, we should assess the demographics data in terms of missing data.\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "## Step 1: Preprocessing\n",
    "\n",
    "### Step 1.1: Assess Missing Data\n",
    "\n",
    "The feature summary file contains a summary of properties for each demographics data column. I will use this file to help me make cleaning decisions during this stage of the project. First of all, we should assess the demographics data in terms of missing data.\n",
    "\n",
    "#### Step 1.1.1: Convert Missing Value Codes to NaNs\n",
    "The fourth column of the feature attributes summary (loaded in above as `feat_info`) documents the codes from the data dictionary that indicate missing or unknown data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feat_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# see what kind of missing code values\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mUnique missing values code in all columns are:\u001b[39m\u001b[39m'\u001b[39m, feat_info[\u001b[39m'\u001b[39m\u001b[39mmissing_or_unknown\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feat_info' is not defined"
     ]
    }
   ],
   "source": [
    "# see what kind of missing code values\n",
    "print('Unique missing values code in all columns are:', feat_info['missing_or_unknown'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feat_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# split feat_infto into two dataframe, one of thim will enter the preprocessing, and the other doesn't need to apply\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# preprocessing on int because it doesn't contain any missing values codes\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m feat_info1 \u001b[39m=\u001b[39m feat_info[feat_info[\u001b[39m'\u001b[39m\u001b[39mmissing_or_unknown\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m[]\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m feat_info2 \u001b[39m=\u001b[39m feat_info[feat_info[\u001b[39m'\u001b[39m\u001b[39mmissing_or_unknown\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m[]\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feat_info' is not defined"
     ]
    }
   ],
   "source": [
    "# split feat_infto into two dataframe, one of thim will enter the preprocessing, and the other doesn't need to apply\n",
    "# preprocessing on int because it doesn't contain any missing values codes\n",
    "feat_info1 = feat_info[feat_info['missing_or_unknown'] != '[]']\n",
    "feat_info2 = feat_info[feat_info['missing_or_unknown'] == '[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feat_info1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# preprocess the columns of missing_or_unknown values codes to make it easy to extract information from it\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m feat_info1[\u001b[39m'\u001b[39m\u001b[39mmissing_or_unknown\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m feat_info1[\u001b[39m'\u001b[39m\u001b[39mmissing_or_unknown\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m      3\u001b[0m feat_info1[\u001b[39m'\u001b[39m\u001b[39mmissing_or_unknown\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m feat_info1[\u001b[39m'\u001b[39m\u001b[39mmissing_or_unknown\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m      4\u001b[0m feat_info1[\u001b[39m'\u001b[39m\u001b[39mmissing_or_unknown\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m feat_info1[\u001b[39m'\u001b[39m\u001b[39mmissing_or_unknown\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feat_info1' is not defined"
     ]
    }
   ],
   "source": [
    "# preprocess the columns of missing_or_unknown values codes to make it easy to extract information from it\n",
    "feat_info1['missing_or_unknown'] = feat_info1['missing_or_unknown'].apply(lambda x: x.replace(\"[\",\"\"))\n",
    "feat_info1['missing_or_unknown'] = feat_info1['missing_or_unknown'].apply(lambda x: x.replace(\"]\",\"\"))\n",
    "feat_info1['missing_or_unknown'] = feat_info1['missing_or_unknown'].apply(lambda x: x.split(\",\"))\n",
    "feat_info1['missing_or_unknown'] = feat_info1['missing_or_unknown'].apply(lambda x: [t if t.isalpha() else int(t) for t in x])\n",
    "feat_info = pd.concat([feat_info1, feat_info2], axis=0)\n",
    "feat_info = feat_info.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feat_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m missing_values_codes \u001b[39m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m columns \u001b[39m=\u001b[39m []\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfor\u001b[39;00m column, missing_value_code \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(feat_info[\u001b[39m\"\u001b[39m\u001b[39mattribute\u001b[39m\u001b[39m\"\u001b[39m],feat_info[\u001b[39m\"\u001b[39m\u001b[39mmissing_or_unknown\u001b[39m\u001b[39m\"\u001b[39m]):\n\u001b[0;32m      5\u001b[0m     missing_values_codes\u001b[39m.\u001b[39mextend(missing_value_code)\n\u001b[0;32m      6\u001b[0m     columns\u001b[39m.\u001b[39mextend([column] \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(missing_value_code))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feat_info' is not defined"
     ]
    }
   ],
   "source": [
    "# Identify missing or unknown data values and convert them to NaNs.\n",
    "missing_values_codes = []\n",
    "columns = []\n",
    "for column, missing_value_code in zip(feat_info[\"attribute\"],feat_info[\"missing_or_unknown\"]):\n",
    "    missing_values_codes.extend(missing_value_code)\n",
    "    columns.extend([column] * len(missing_value_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert missing values codes to Nans\n",
    "for attribute , code in zip(columns, missing_values_codes):\n",
    "    azdias[attribute] = azdias[attribute].apply(lambda x: np.NAN if x == code else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1408060312.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[19], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    How much missing data is present in each column? There are a few columns that are outliers in terms of the proportion of values that are missing.\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#### Step 1.1.2: Assess Missing Data in Each Column\n",
    "\n",
    "How much missing data is present in each column? There are a few columns that are outliers in terms of the proportion of values that are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'azdias' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Perform an assessment of how much missing data there is in each column of the\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# dataset.\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m proportion_missing_values \u001b[39m=\u001b[39m azdias\u001b[39m.\u001b[39misna()\u001b[39m.\u001b[39mmean()\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m col , proportion \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(azdias\u001b[39m.\u001b[39mcolumns, proportion_missing_values):\n\u001b[0;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe proportion of values that are missing in \u001b[39m\u001b[39m\"\u001b[39m , col , \u001b[39m\"\u001b[39m\u001b[39m column is \u001b[39m\u001b[39m\"\u001b[39m, proportion)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'azdias' is not defined"
     ]
    }
   ],
   "source": [
    "# Perform an assessment of how much missing data there is in each column of the\n",
    "# dataset.\n",
    "proportion_missing_values = azdias.isna().mean()\n",
    "for col , proportion in zip(azdias.columns, proportion_missing_values):\n",
    "    print(\"The proportion of values that are missing in \" , col , \" column is \", proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Investigate patterns in the amount of missing data in each column.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m17\u001b[39m,\u001b[39m10\u001b[39m))\n\u001b[0;32m      3\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m\"\u001b[39m\u001b[39mThe patterns in amount of missing data in each column\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[39m.\u001b[39mhist(proportion_missing_values,rwidth\u001b[39m=\u001b[39m\u001b[39m0.96\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Investigate patterns in the amount of missing data in each column.\n",
    "plt.figure(figsize=(17,10))\n",
    "plt.title(\"The patterns in amount of missing data in each column\")\n",
    "plt.hist(proportion_missing_values,rwidth=0.96)\n",
    "plt.xlabel('Proportion of Missing Values')\n",
    "plt.ylabel('Number of Columns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Remove the outlier columns from the dataset.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m17\u001b[39m,\u001b[39m10\u001b[39m))\n\u001b[0;32m      3\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m\"\u001b[39m\u001b[39mBoxplot for Proportion of Missing Values in each attribute\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[39m.\u001b[39mboxplot(proportion_missing_values,vert\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Remove the outlier columns from the dataset.\n",
    "plt.figure(figsize=(17,10))\n",
    "plt.title(\"Boxplot for Proportion of Missing Values in each attribute\")\n",
    "plt.boxplot(proportion_missing_values,vert=False)\n",
    "plt.xlabel('Proportion of Missing Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# remove outliers columns\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m Q1_col \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mquantile(proportion_missing_values, \u001b[39m0.25\u001b[39m)\n\u001b[0;32m      3\u001b[0m Q3_col \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mquantile(proportion_missing_values, \u001b[39m0.75\u001b[39m)\n\u001b[0;32m      4\u001b[0m IQR_col \u001b[39m=\u001b[39m Q3_col \u001b[39m-\u001b[39m Q1_col\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# remove outliers columns\n",
    "Q1_col = np.quantile(proportion_missing_values, 0.25)\n",
    "Q3_col = np.quantile(proportion_missing_values, 0.75)\n",
    "IQR_col = Q3_col - Q1_col\n",
    "lower_bound_col = Q1_col - (1.5 * IQR_col)\n",
    "upper_bound_col = Q3_col + (1.5 * IQR_col)\n",
    "removed_columns = []\n",
    "for col , proportion in zip(proportion_missing_values.index , proportion_missing_values):\n",
    "    if proportion >= upper_bound_col or proportion <= lower_bound_col: removed_columns.append(col)\n",
    "print('Removed Columns are:', removed_columns)\n",
    "azdias_dropped_columns = azdias.drop(removed_columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2394730673.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[24], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    There is a pattern in the missing values that, the majority of columns in the dataset by a percentage of **93%** are all fall in the range from **0%** to **20%** proportion of missing values in each column, and there exist a small fraction of the dataset columns that have huge numebr of missing values compared to any other columns they are **6** columns having more than **30%**  proportion of missing values in each column, we will drop these columns from our dataset.\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "There is a pattern in the missing values that, the majority of columns in the dataset by a percentage of **93%** are all fall in the range from **0%** to **20%** proportion of missing values in each column, and there exist a small fraction of the dataset columns that have huge numebr of missing values compared to any other columns they are **6** columns having more than **30%**  proportion of missing values in each column, we will drop these columns from our dataset.\n",
    "\n",
    "The outliers columns that will be dropped are:\n",
    "- **AGER_TYP**\n",
    "- **GEBURTSJAHR**\n",
    "- **TITEL_KZ**\n",
    "- **ALTER_HH**\n",
    "- **KK_KUNDENTYP**\n",
    "- **KBA05_BAUMAX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3709695748.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[25], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    How much data is missing in each row? As with the columns, we should see some groups of points that have a very different numbers of missing values. we will Divide the data into two subsets: one for data points that are above some threshold for missing values, and a second subset for points below that threshold.\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#### Step 1.1.3: Assess Missing Data in Each Row\n",
    "\n",
    "How much data is missing in each row? As with the columns, we should see some groups of points that have a very different numbers of missing values. we will Divide the data into two subsets: one for data points that are above some threshold for missing values, and a second subset for points below that threshold.\n",
    "\n",
    "In order to know what to do with the outlier rows, we should see if the distribution of data values on columns that are not missing data (or are missing very little data) are similar or different between the two groups. we will Select at least five of these columns and compare the distribution of values.\n",
    "\n",
    "Depending on what we observe in our comparison, this will have implications on how we approach our conclusions later in the analysis. If the distributions of non-missing features look similar between the data with many missing values and the data with few or no missing values, then we could argue that simply dropping those points from the analysis won't present a major issue. On the other hand, if the data with many missing values looks very different from the data with few or no missing values, then we should make a note on those data as special."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'azdias_dropped_columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# How much data is missing in each row of the dataset?\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m azdias_dropped_columns[\u001b[39m\"\u001b[39m\u001b[39mNAN count\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m azdias_dropped_columns\u001b[39m.\u001b[39misna()\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe number of missing values in each row of the dataset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(azdias_dropped_columns[\u001b[39m\"\u001b[39m\u001b[39mNAN count\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'azdias_dropped_columns' is not defined"
     ]
    }
   ],
   "source": [
    "# How much data is missing in each row of the dataset?\n",
    "azdias_dropped_columns[\"NAN count\"] = azdias_dropped_columns.isna().sum(axis=1)\n",
    "print(\"The number of missing values in each row of the dataset\")\n",
    "print(azdias_dropped_columns[\"NAN count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m17\u001b[39m,\u001b[39m10\u001b[39m))\n\u001b[0;32m      2\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mBoxplot for Number of Missing Values in each row\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[39m.\u001b[39mboxplot(azdias_dropped_columns[\u001b[39m\"\u001b[39m\u001b[39mNAN count\u001b[39m\u001b[39m\"\u001b[39m],vert\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(17,10))\n",
    "plt.title('Boxplot for Number of Missing Values in each row')\n",
    "plt.boxplot(azdias_dropped_columns[\"NAN count\"],vert=False)\n",
    "plt.xlabel('Number of Missing Values in each row')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# code to divide the data into two subsets based on the number of missing\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# values in each row.\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m Q1_row \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mquantile(azdias_dropped_columns[\u001b[39m\"\u001b[39m\u001b[39mNAN count\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m0.25\u001b[39m)\n\u001b[0;32m      4\u001b[0m Q3_row \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mquantile(azdias_dropped_columns[\u001b[39m\"\u001b[39m\u001b[39mNAN count\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m0.75\u001b[39m)\n\u001b[0;32m      5\u001b[0m IQR_row \u001b[39m=\u001b[39m Q3_row \u001b[39m-\u001b[39m Q1_row\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# code to divide the data into two subsets based on the number of missing\n",
    "# values in each row.\n",
    "Q1_row = np.quantile(azdias_dropped_columns[\"NAN count\"], 0.25)\n",
    "Q3_row = np.quantile(azdias_dropped_columns[\"NAN count\"], 0.75)\n",
    "IQR_row = Q3_row - Q1_row\n",
    "upper_bound_row = np.ceil(Q3_row + (1.5 * IQR_row))\n",
    "# Data with many missing values\n",
    "first_subset = azdias_dropped_columns.loc[azdias_dropped_columns[\"NAN count\"] >= upper_bound_row]\n",
    "# Data with few or no missing values\n",
    "second_subset = azdias_dropped_columns.loc[azdias_dropped_columns[\"NAN count\"] < upper_bound_row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'proportion_missing_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m         sns\u001b[39m.\u001b[39mcountplot(x\u001b[39m=\u001b[39mcolumn_name, data\u001b[39m=\u001b[39mdata2, ax\u001b[39m=\u001b[39max[\u001b[39m1\u001b[39m])\n\u001b[0;32m     35\u001b[0m         ax[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mset_title(sub_title2)\n\u001b[1;32m---> 36\u001b[0m columns_names \u001b[39m=\u001b[39m [col \u001b[39mfor\u001b[39;00m col, value \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(proportion_missing_values\u001b[39m.\u001b[39mindex, proportion_missing_values) \u001b[39mif\u001b[39;00m value \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m]\n\u001b[0;32m     37\u001b[0m \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m columns_names:\n\u001b[0;32m     38\u001b[0m     countplot(first_subset, second_subset, col, \u001b[39m\"\u001b[39m\u001b[39mDistribution of data values\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mData with many missing values\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     39\u001b[0m              \u001b[39m\"\u001b[39m\u001b[39mData with few or no missing values\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'proportion_missing_values' is not defined"
     ]
    }
   ],
   "source": [
    "# Compare the distribution of values for at least five columns where there are\n",
    "# no or few missing values, between the two subsets.\n",
    "def countplot(data1, data2, column_name, super_title, sub_title1, sub_title2, mode='count'):\n",
    "    \"\"\"\n",
    "    This function creates a countplot of a column of data in two different data sets. The plot is divided into two subplots, \n",
    "    with the option to display the count of occurrences or the proportion of occurrences.\n",
    "\n",
    "    Parameters:\n",
    "    data1 (pandas dataframe): The first data set to be plotted.\n",
    "    data2 (pandas dataframe): The second data set to be plotted.\n",
    "    column_name (str): The name of the column to be plotted.\n",
    "    super_title (str): The title of the entire plot.\n",
    "    sub_title1 (str): The title of the first subplot.\n",
    "    sub_title2 (str): The title of the second subplot.\n",
    "    mode (str, optional): The mode of the plot. Can be either 'count' (default) or 'proportion'.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    figure , ax = plt.subplots(1,2)\n",
    "    figure.suptitle(super_title)\n",
    "    figure.set_figheight(7)\n",
    "    figure.set_figwidth(18)\n",
    "    if mode == 'proportion':\n",
    "        proportions_1 = data1[column_name].value_counts(normalize=True)\n",
    "        proportions_2 = data2[column_name].value_counts(normalize=True)\n",
    "        sns.barplot(x=proportions_1.index, y=proportions_1.values, ax=ax[0])\n",
    "        ax[0].set_title(sub_title1)\n",
    "        sns.barplot(x=proportions_2.index, y=proportions_2.values, ax=ax[1])\n",
    "        ax[1].set_title(sub_title2)\n",
    "    elif mode == 'count':\n",
    "        sns.countplot(x=column_name, data=data1, ax=ax[0])\n",
    "        ax[0].set_title(sub_title1)\n",
    "        sns.countplot(x=column_name, data=data2, ax=ax[1])\n",
    "        ax[1].set_title(sub_title2)\n",
    "columns_names = [col for col, value in zip(proportion_missing_values.index, proportion_missing_values) if value == 0]\n",
    "for col in columns_names:\n",
    "    countplot(first_subset, second_subset, col, \"Distribution of data values\", \"Data with many missing values\",\n",
    "             \"Data with few or no missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SimpleImputer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# initialize different imputers\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m categorical_mixed_imputer \u001b[39m=\u001b[39m SimpleImputer(missing_values\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mNAN, strategy\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmost_frequent\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m numerical_imputer \u001b[39m=\u001b[39m SimpleImputer(missing_values\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mNAN, strategy\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m ordinal_imputer \u001b[39m=\u001b[39m SimpleImputer(missing_values\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mNAN, strategy\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmedian\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SimpleImputer' is not defined"
     ]
    }
   ],
   "source": [
    "# initialize different imputers\n",
    "categorical_mixed_imputer = SimpleImputer(missing_values= np.NAN, strategy= \"most_frequent\")\n",
    "numerical_imputer = SimpleImputer(missing_values= np.NAN, strategy= \"mean\")\n",
    "ordinal_imputer = SimpleImputer(missing_values= np.NAN, strategy= \"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(df, flag= 'customer'):\n",
    "    \"\"\"\n",
    "    This function imputes missing values in a DataFrame. It imputes different data types differently.\n",
    "    For categorical and mixed type columns, it uses the 'most_frequent' strategy.\n",
    "    For numerical type columns, it uses the 'mean' strategy.\n",
    "    For ordinal type columns, it uses the 'median' strategy.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The DataFrame which has missing values to be imputed.\n",
    "    flag: a string input that has two inputs, the first is 'customer' which means he will apply only transformations from \n",
    "    imputer on the data, and will not make the fit step, while 'general' means he will fit the imputer on this data\n",
    "    \n",
    "    Returns:\n",
    "    df (pandas.DataFrame): The DataFrame with imputed missing values.\n",
    "    \n",
    "    \"\"\"\n",
    "    # impute categorical and mixed data types features\n",
    "    categorical_mixed_cols = feat_info[(feat_info['type'] == 'categorical') | (feat_info['type'] == 'mixed')].attribute\n",
    "    categorical_mixed_cols = categorical_mixed_cols.apply(lambda x: x if x in df.columns else np.NAN).dropna().to_list()\n",
    "    if flag == 'general':\n",
    "        categorical_mixed_imputer.fit(df[categorical_mixed_cols])\n",
    "        imputed_categorical_mixed_columns = categorical_mixed_imputer.transform(df[categorical_mixed_cols])\n",
    "    elif flag == 'customer':\n",
    "        imputed_categorical_mixed_columns = categorical_mixed_imputer.transform(df[categorical_mixed_cols])\n",
    "    imputed_categorical_mixed_columns = pd.DataFrame(imputed_categorical_mixed_columns, index= df.index, columns= categorical_mixed_cols)\n",
    "    df = df.drop(columns=categorical_mixed_cols)\n",
    "    df = pd.concat([df, imputed_categorical_mixed_columns], axis=1)\n",
    "    # impute numerical data types features\n",
    "    numerical_cols = feat_info[feat_info['type'] == 'numeric'].attribute\n",
    "    numerical_cols = numerical_cols.apply(lambda x: x if x in df.columns else np.NAN).dropna().to_list()\n",
    "    if flag == 'general':\n",
    "        numerical_imputer.fit(df[numerical_cols])\n",
    "        imputed_numerical_columns = numerical_imputer.transform(df[numerical_cols])\n",
    "    elif flag == 'customer':\n",
    "        imputed_numerical_columns = numerical_imputer.transform(df[numerical_cols])\n",
    "    imputed_numerical_columns = pd.DataFrame(imputed_numerical_columns, index= df.index, columns= numerical_cols)\n",
    "    df = df.drop(columns=numerical_cols)\n",
    "    df = pd.concat([df, imputed_numerical_columns], axis=1)\n",
    "    # impute ordinal data types features\n",
    "    ordinal_cols = feat_info[feat_info['type'] == 'ordinal'].attribute\n",
    "    ordinal_cols = ordinal_cols.apply(lambda x: x if x in df.columns else np.NAN).dropna().to_list()\n",
    "    if flag == 'general':\n",
    "        ordinal_imputer.fit(df[ordinal_cols])\n",
    "        imputed_ordinal_columns = ordinal_imputer.transform(df[ordinal_cols])\n",
    "    elif flag == 'customer':\n",
    "        imputed_ordinal_columns = ordinal_imputer.transform(df[ordinal_cols])\n",
    "    imputed_ordinal_columns = pd.DataFrame(imputed_ordinal_columns, index= df.index, columns= ordinal_cols)\n",
    "    df = df.drop(columns=ordinal_cols)\n",
    "    df = pd.concat([df, imputed_ordinal_columns], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'second_subset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# impute the missing values in each column before encoding steps\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m second_subset \u001b[39m=\u001b[39m fill_missing_values(second_subset, \u001b[39m'\u001b[39m\u001b[39mgeneral\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'second_subset' is not defined"
     ]
    }
   ],
   "source": [
    "# impute the missing values in each column before encoding steps\n",
    "second_subset = fill_missing_values(second_subset, 'general')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4189532817.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[33], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    the distributions of non-missing features look similar between the data with many missing values and the data with few or no missing values in **ANREDE_KZ** feature only, but they are different in the rest of the features, so i decided not to drop any data points because they are special\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "the distributions of non-missing features look similar between the data with many missing values and the data with few or no missing values in **ANREDE_KZ** feature only, but they are different in the rest of the features, so i decided not to drop any data points because they are special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3617485553.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[34], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    - For numeric and interval data, these features can be kept without changes.\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "### Step 1.2: Select and Re-Encode Features\n",
    "\n",
    "- For numeric and interval data, these features can be kept without changes.\n",
    "- Most of the variables in the dataset are ordinal in nature. While ordinal values may technically be non-linear in spacing, make the simplifying assumption that the ordinal variables can be treated as being interval in nature (that is, kept without any changes).\n",
    "- Special handling may be necessary for the remaining two variable types: categorical, and 'mixed'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feat_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# How many features are there of each data type?\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m feature__data_type_count \u001b[39m=\u001b[39m feat_info[\u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalue_counts()\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m data_type, count \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(feature__data_type_count\u001b[39m.\u001b[39mindex, feature__data_type_count):\n\u001b[0;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThere are \u001b[39m\u001b[39m\"\u001b[39m, count , \u001b[39m\"\u001b[39m\u001b[39m Features in \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m data type\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(data_type))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feat_info' is not defined"
     ]
    }
   ],
   "source": [
    "# How many features are there of each data type?\n",
    "feature__data_type_count = feat_info['type'].value_counts()\n",
    "for data_type, count in zip(feature__data_type_count.index, feature__data_type_count):\n",
    "    print(\"There are \", count , \" Features in {} data type\".format(data_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1795927280.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[36], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    For categorical data, we would ordinarily need to encode the levels as dummy variables. Depending on the number of categories, perform one of the following:\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#### Step 1.2.1: Re-Encode Categorical Features\n",
    "\n",
    "For categorical data, we would ordinarily need to encode the levels as dummy variables. Depending on the number of categories, perform one of the following:\n",
    "- For binary (two-level) categoricals that take numeric values, we can keep them without needing to do anything.\n",
    "- There is one binary variable that takes on non-numeric values. For this one, we need to re-encode the values as numbers or create a dummy variable.\n",
    "- For multi-level categoricals (three or more values), you can choose to encode the values using multiple dummy variables, or (to keep things straightforward) just drop them from the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'second_subset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# drop GEBAEUDETYP feature as we will not re-encode it because it has different values distribution and will obstacle\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# the process of applying transformations on the customer data, as this feature in customer data has different value\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# distribtuion and this will lead to conflicts\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m second_subset \u001b[39m=\u001b[39m second_subset\u001b[39m.\u001b[39mdrop(columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mGEBAEUDETYP\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'second_subset' is not defined"
     ]
    }
   ],
   "source": [
    "# drop GEBAEUDETYP feature as we will not re-encode it because it has different values distribution and will obstacle\n",
    "# the process of applying transformations on the customer data, as this feature in customer data has different value\n",
    "# distribtuion and this will lead to conflicts\n",
    "second_subset = second_subset.drop(columns = ['GEBAEUDETYP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feat_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Assess categorical variables: which are binary, which are multi-level, and\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# which one needs to be re-encoded?\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m categorical \u001b[39m=\u001b[39m feat_info[feat_info[\u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcategorical\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mattribute\n\u001b[0;32m      4\u001b[0m categorical \u001b[39m=\u001b[39m categorical\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x \u001b[39mif\u001b[39;00m x \u001b[39min\u001b[39;00m second_subset\u001b[39m.\u001b[39mcolumns \u001b[39melse\u001b[39;00m np\u001b[39m.\u001b[39mNAN)\u001b[39m.\u001b[39mdropna()\n\u001b[0;32m      5\u001b[0m categorical_levels \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mbinary-level\u001b[39m\u001b[39m'\u001b[39m:[], \u001b[39m'\u001b[39m\u001b[39mbinary-level-re-encoded\u001b[39m\u001b[39m'\u001b[39m:[],\u001b[39m'\u001b[39m\u001b[39mmulti-level-re-encoded\u001b[39m\u001b[39m'\u001b[39m:[]}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feat_info' is not defined"
     ]
    }
   ],
   "source": [
    "# Assess categorical variables: which are binary, which are multi-level, and\n",
    "# which one needs to be re-encoded?\n",
    "categorical = feat_info[feat_info['type'] == 'categorical'].attribute\n",
    "categorical = categorical.apply(lambda x: x if x in second_subset.columns else np.NAN).dropna()\n",
    "categorical_levels = {'binary-level':[], 'binary-level-re-encoded':[],'multi-level-re-encoded':[]}\n",
    "for categorical_col in categorical:\n",
    "    unique_categories = pd.Series(second_subset[categorical_col].unique()).dropna().to_list()\n",
    "    if len(unique_categories) == 2:\n",
    "        if str(unique_categories[0]).isalpha() or str(unique_categories[1]).isalpha():\n",
    "            categorical_levels['binary-level-re-encoded'].append(categorical_col)\n",
    "        else:\n",
    "            categorical_levels['binary-level'].append(categorical_col)\n",
    "    elif len(unique_categories) > 2:\n",
    "        categorical_levels['multi-level-re-encoded'].append(categorical_col)\n",
    "for key, value in  categorical_levels.items():\n",
    "    print('============================================')\n",
    "    for val in value:\n",
    "        print('The attribute ' , val , 'is' , key)\n",
    "    print('============================================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'categorical_levels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# preprocessing for multi-level attributes to be able to convert them to multiple dummy variables\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfor\u001b[39;00m categorical_col \u001b[39min\u001b[39;00m categorical_levels[\u001b[39m'\u001b[39m\u001b[39mmulti-level-re-encoded\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m      3\u001b[0m     second_subset\u001b[39m.\u001b[39mloc[:, categorical_col] \u001b[39m=\u001b[39m second_subset[categorical_col]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x \u001b[39mif\u001b[39;00m \u001b[39mstr\u001b[39m(x)\u001b[39m.\u001b[39misalpha() \u001b[39melse\u001b[39;00m \u001b[39mstr\u001b[39m(x))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'categorical_levels' is not defined"
     ]
    }
   ],
   "source": [
    "# preprocessing for multi-level attributes to be able to convert them to multiple dummy variables\n",
    "for categorical_col in categorical_levels['multi-level-re-encoded']:\n",
    "    second_subset.loc[:, categorical_col] = second_subset[categorical_col].apply(lambda x: x if str(x).isalpha() else str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'second_subset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Re-encode categorical variable(s) to be kept in the analysis.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# re-encode binary-level attribute\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m second_subset[categorical_levels[\u001b[39m'\u001b[39m\u001b[39mbinary-level-re-encoded\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]] \u001b[39m=\u001b[39m second_subset[categorical_levels[\u001b[39m'\u001b[39m\u001b[39mbinary-level-re-encoded\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m x \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mW\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[39m# re-encode multi-level attribute\u001b[39;00m\n\u001b[0;32m      5\u001b[0m multiple_dummy_attributes \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mget_dummies(second_subset[categorical_levels[\u001b[39m'\u001b[39m\u001b[39mmulti-level-re-encoded\u001b[39m\u001b[39m'\u001b[39m]])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'second_subset' is not defined"
     ]
    }
   ],
   "source": [
    "# Re-encode categorical variable(s) to be kept in the analysis.\n",
    "# re-encode binary-level attribute\n",
    "second_subset[categorical_levels['binary-level-re-encoded'][0]] = second_subset[categorical_levels['binary-level-re-encoded'][0]].apply(lambda x: 0 if x == 'W' else 1)\n",
    "# re-encode multi-level attribute\n",
    "multiple_dummy_attributes = pd.get_dummies(second_subset[categorical_levels['multi-level-re-encoded']])\n",
    "second_subset = pd.concat([second_subset, multiple_dummy_attributes],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3526015070.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[41], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    re-encoded the binary variable that has non numerical values, and replaced its non numerical representation of categorical levels with two number representation for each categorical level and the two numbers are **0** and **1**, the multi-level attributes choose to drop one of them which is **GEBAEUDETYP** because in general demographics it has different values distribution than in customer demographics which will lead to conflicts and for the others multi-level attributes, instead re-encoded them, and replaced these attributes with the new multiple dummy attributes\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "re-encoded the binary variable that has non numerical values, and replaced its non numerical representation of categorical levels with two number representation for each categorical level and the two numbers are **0** and **1**, the multi-level attributes choose to drop one of them which is **GEBAEUDETYP** because in general demographics it has different values distribution than in customer demographics which will lead to conflicts and for the others multi-level attributes, instead re-encoded them, and replaced these attributes with the new multiple dummy attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3718106776.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[42], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    There are a handful of features that are marked as \"mixed\" in the feature summary that require special treatment in order to be included in the analysis. There are two in particular that deserve attention; the handling of the rest are up to your own choices:\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#### Step 1.2.2: Engineer Mixed-Type Features\n",
    "\n",
    "There are a handful of features that are marked as \"mixed\" in the feature summary that require special treatment in order to be included in the analysis. There are two in particular that deserve attention; the handling of the rest are up to your own choices:\n",
    "- \"PRAEGENDE_JUGENDJAHRE\" combines information on three dimensions: generation by decade, movement (mainstream vs. avantgarde), and nation (east vs. west). While there aren't enough levels to disentangle east from west, I should create two new variables to capture the other two dimensions: an interval-type variable for decade, and a binary variable for movement.\n",
    "- \"CAMEO_INTL_2015\" combines information on two axes: wealth and life stage. Break up the two-digit codes by their 'tens'-place and 'ones'-place digits into two new ordinal variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movement_encoding(x):\n",
    "    \"\"\"\n",
    "    Encodes an input value into a binary value for movement.\n",
    "    \n",
    "    Parameters:\n",
    "    x (int): The input value to be encoded.\n",
    "    \n",
    "    Returns:\n",
    "    int: The encoded binary value. 0 for mainstream, 1 for avantgrade.\n",
    "    if x not in any of the above return x \n",
    "    \n",
    "    \"\"\"\n",
    "    mainstream_codes = [1, 3, 5, 8, 10, 12, 14]\n",
    "    avantgrade_codes = [2, 4, 6, 7, 9, 11, 13, 15]\n",
    "    if x in mainstream_codes:\n",
    "        x = 0\n",
    "    elif x in avantgrade_codes:\n",
    "        x = 1\n",
    "    else:\n",
    "        x = x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decade_encoding(x):\n",
    "    \"\"\"\n",
    "    Encodes an input value into a discrete value for decade.\n",
    "    \n",
    "    Parameters:\n",
    "    x (int): The input value to be encoded.\n",
    "    \n",
    "    Returns:\n",
    "    int: The encoded discrete value representing a decade.\n",
    "    if x = 1 or 2 return 0 (40s)\n",
    "    if x = 3 or 4 return 1 (50s)\n",
    "    if x = 5 or 6 or 7 return 2 (60s)\n",
    "    if x = 8 or 9 return 3 (70s)\n",
    "    if x = 10 or 11 or 12 return 4 (80s)\n",
    "    if x = 13 or 14 or 15 return 5 (90s)\n",
    "    if x not in any of the above return x \n",
    "    \n",
    "    \"\"\"\n",
    "    decade_40s = [1, 2]\n",
    "    decade_50s = [3, 4]\n",
    "    decade_60s = [5, 6, 7]\n",
    "    decade_70s = [8, 9]\n",
    "    decade_80s = [10, 11, 12]\n",
    "    decade_90s = [13, 14, 15]\n",
    "    if x in decade_40s:\n",
    "        x = 0\n",
    "    elif x in decade_50s:\n",
    "        x = 1\n",
    "    elif x in decade_60s:\n",
    "        x = 2\n",
    "    elif x in decade_70s:\n",
    "        x = 3\n",
    "    elif x in decade_80s:\n",
    "        x = 4\n",
    "    elif x in decade_90s:\n",
    "        x = 5\n",
    "    else:\n",
    "        x = x \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wealth_encoding(x):\n",
    "    \"\"\"\n",
    "    Encodes an input value into a discrete value for wealth.\n",
    "    \n",
    "    Parameters:\n",
    "    x (int): The input value to be encoded.\n",
    "    \n",
    "    Returns:\n",
    "    int: The encoded discrete value representing a wealth.\n",
    "    if x in wealthy_households return 0\n",
    "    if x in prosperous_households return 1\n",
    "    if x in comfortable_households return 2\n",
    "    if x in less_affluent_households return 3\n",
    "    if x in poorer_households return 4\n",
    "    if x not in any of the above return x \n",
    "    \n",
    "    \"\"\"\n",
    "    wealthy_households = [11,12,13,14,15]\n",
    "    prosperous_households = [21,22,23,24,25]\n",
    "    comfortable_households = [31,32,33,34,35]\n",
    "    less_affluent_households = [41,42,43,44,45]\n",
    "    poorer_households = [51,52,53,54,55]\n",
    "    if x in wealthy_households:\n",
    "        x = 0\n",
    "    elif x in prosperous_households:\n",
    "        x = 1\n",
    "    elif x in comfortable_households:\n",
    "        x = 2\n",
    "    elif x in less_affluent_households:\n",
    "        x = 3\n",
    "    elif x in poorer_households:\n",
    "        x = 4\n",
    "    else:\n",
    "        x = x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def life_stage_encoding(x):\n",
    "    \"\"\"\n",
    "    Encodes an input value into a discrete value for life stage.\n",
    "    \n",
    "    Parameters:\n",
    "    x (int): The input value to be encoded.\n",
    "    \n",
    "    Returns:\n",
    "    int: The encoded discrete value representing a life stage.\n",
    "    if x in pre_family_couples_and_singles return 0\n",
    "    if x in young_couples_with_children return 1\n",
    "    if x in families_with_school_age_children return 2\n",
    "    if x in older_families_and_mature_couples return 3\n",
    "    if x in elders_in_retirement return 4\n",
    "    if x not in any of the above return x \n",
    "    \n",
    "    \"\"\"\n",
    "    pre_family_couples_and_singles = [11,21,31,41,51]\n",
    "    young_couples_with_children = [12,22,32,42,52]\n",
    "    families_with_school_age_children = [13,23,33,43,53]\n",
    "    older_families_and_mature_couples = [14,24,34,44,54]\n",
    "    elders_in_retirement = [15,25,35,45,55]\n",
    "    if x in pre_family_couples_and_singles:\n",
    "        x = 0\n",
    "    elif x in young_couples_with_children:\n",
    "        x = 1\n",
    "    elif x in families_with_school_age_children:\n",
    "        x = 2\n",
    "    elif x in older_families_and_mature_couples:\n",
    "        x = 3\n",
    "    elif x in elders_in_retirement:\n",
    "        x = 4\n",
    "    else:\n",
    "        x = x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'second_subset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Investigate \"PRAEGENDE_JUGENDJAHRE\" and engineer two new variables.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# Create first variable movement wiht two bianry values: 0 for avantgarde and 1 for mainstream\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m second_subset[\u001b[39m'\u001b[39m\u001b[39mmovement\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m second_subset[\u001b[39m'\u001b[39m\u001b[39mPRAEGENDE_JUGENDJAHRE\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(movement_encoding)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Create second variable decade with multi-values: 0 for 40s and 1 for 50s and 2 for 60s \u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m# and 3 for 70s and 4 for 80s and 5 for 90s\u001b[39;00m\n\u001b[0;32m      6\u001b[0m second_subset[\u001b[39m'\u001b[39m\u001b[39mdecade\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m second_subset[\u001b[39m'\u001b[39m\u001b[39mPRAEGENDE_JUGENDJAHRE\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(decade_encoding)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'second_subset' is not defined"
     ]
    }
   ],
   "source": [
    "# Investigate \"PRAEGENDE_JUGENDJAHRE\" and engineer two new variables.\n",
    "# Create first variable movement wiht two bianry values: 0 for avantgarde and 1 for mainstream\n",
    "second_subset['movement'] = second_subset['PRAEGENDE_JUGENDJAHRE'].apply(movement_encoding)\n",
    "# Create second variable decade with multi-values: 0 for 40s and 1 for 50s and 2 for 60s \n",
    "# and 3 for 70s and 4 for 80s and 5 for 90s\n",
    "second_subset['decade'] = second_subset['PRAEGENDE_JUGENDJAHRE'].apply(decade_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'second_subset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Investigate \"CAMEO_INTL_2015\" and engineer two new variables.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m second_subset[\u001b[39m\"\u001b[39m\u001b[39mCAMEO_INTL_2015\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m=\u001b[39m second_subset[\u001b[39m\"\u001b[39m\u001b[39mCAMEO_INTL_2015\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39m# Create first variable wealth with multi-values: 0 for (11,12,13,14,15) and 1 for (21,22,23,24,25) and 2 for (31,32,33,34,35)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# and 3 for (41,42,43,44,45) and 4 for (51,52,53,54,55)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m second_subset[\u001b[39m'\u001b[39m\u001b[39mwealth\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m second_subset[\u001b[39m'\u001b[39m\u001b[39mCAMEO_INTL_2015\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(wealth_encoding)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'second_subset' is not defined"
     ]
    }
   ],
   "source": [
    "# Investigate \"CAMEO_INTL_2015\" and engineer two new variables.\n",
    "second_subset[\"CAMEO_INTL_2015\"]= second_subset[\"CAMEO_INTL_2015\"].astype(float)\n",
    "# Create first variable wealth with multi-values: 0 for (11,12,13,14,15) and 1 for (21,22,23,24,25) and 2 for (31,32,33,34,35)\n",
    "# and 3 for (41,42,43,44,45) and 4 for (51,52,53,54,55)\n",
    "second_subset['wealth'] = second_subset['CAMEO_INTL_2015'].apply(wealth_encoding)\n",
    "# create second variable life_stage with multi-values: 0 for (11,21,31,41,51) and 1 for (12,22,32,42,52)\n",
    "# and 2 for (13,23,33,43,53) and 3 for (14,24,34,44,54) and 4 for (15,25,35,45,55)\n",
    "second_subset['life_stage'] = second_subset['CAMEO_INTL_2015'].apply(life_stage_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3224485307.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[49], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    Created two variables **decade** and **movement** from **PRAEGENDE_JUGENDJAHRE** then deleted the original column and kept the new two variables, then make new two variables **life_stage** and **wealth** from **CAMEO_INTL_2015** and removed the original column and kept the new two variables\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Created two variables **decade** and **movement** from **PRAEGENDE_JUGENDJAHRE** then deleted the original column and kept the new two variables, then make new two variables **life_stage** and **wealth** from **CAMEO_INTL_2015** and removed the original column and kept the new two variables\n",
    "\n",
    "decided to keep the following mixed features without any feature engineering preprocessing because they were will distinguished in their original encoding\n",
    "\n",
    "- **WOHNLAGE**\n",
    "- **KBA05_BAUMAX**\n",
    "- **PLZ8_BAUMAX**\n",
    "\n",
    "decided also to remove the following features because there is not enough informations to help me distinguish between different dimensions represented in each feature\n",
    "\n",
    "- **LP_LEBENSPHASE_FEIN**\n",
    "- **LP_LEBENSPHASE_GROB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (525677814.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[50], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    The dataframe should consist of the following:\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#### Step 1.2.3: Complete Feature Selection\n",
    "\n",
    "The dataframe should consist of the following:\n",
    "- All numeric, interval, and ordinal type columns from the original dataset.\n",
    "- Binary categorical features (all numerically-encoded).\n",
    "- Engineered features from other multi-level categorical features and mixed features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'second_subset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Delete all useless columns\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m second_subset \u001b[39m=\u001b[39m second_subset\u001b[39m.\u001b[39mdrop([\u001b[39m\"\u001b[39m\u001b[39mPRAEGENDE_JUGENDJAHRE\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mCAMEO_INTL_2015\u001b[39m\u001b[39m\"\u001b[39m], axis\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m second_subset \u001b[39m=\u001b[39m second_subset\u001b[39m.\u001b[39mdrop(categorical_levels[\u001b[39m'\u001b[39m\u001b[39mmulti-level-re-encoded\u001b[39m\u001b[39m'\u001b[39m],axis\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'second_subset' is not defined"
     ]
    }
   ],
   "source": [
    "# Delete all useless columns\n",
    "second_subset = second_subset.drop([\"PRAEGENDE_JUGENDJAHRE\", \"CAMEO_INTL_2015\"], axis= 1)\n",
    "second_subset = second_subset.drop(categorical_levels['multi-level-re-encoded'],axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'second_subset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m second_subset \u001b[39m=\u001b[39m second_subset\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mLP_LEBENSPHASE_FEIN\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLP_LEBENSPHASE_GROB\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      2\u001b[0m second_subset \u001b[39m=\u001b[39m second_subset\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mNAN count\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'second_subset' is not defined"
     ]
    }
   ],
   "source": [
    "second_subset = second_subset.drop(columns=['LP_LEBENSPHASE_FEIN', 'LP_LEBENSPHASE_GROB'])\n",
    "second_subset = second_subset.drop(columns=[\"NAN count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 1.3: Create a Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df,feat_info):\n",
    "    \"\"\"\n",
    "    Perform feature trimming, re-encoding, and engineering for demographics\n",
    "    data\n",
    "    \n",
    "    INPUT: Demographics DataFrame\n",
    "    OUTPUT: Trimmed and cleaned demographics DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # Put in code here to execute all main cleaning steps:\n",
    "    # convert missing value codes into NaNs, ...\n",
    "    missing_values_codes = []\n",
    "    columns = []\n",
    "    for column, missing_value_code in zip(feat_info[\"attribute\"],feat_info[\"missing_or_unknown\"]):\n",
    "        missing_values_codes.extend(missing_value_code)\n",
    "        columns.extend([column] * len(missing_value_code))\n",
    "    for attribute , code in zip(columns, missing_values_codes):\n",
    "        df[attribute] = df[attribute].apply(lambda x: np.NAN if x == code else x)\n",
    "    # remove selected columns and rows, ...\n",
    "    removed_columns = ['AGER_TYP', 'GEBURTSJAHR', 'TITEL_KZ', 'ALTER_HH', 'KK_KUNDENTYP', 'KBA05_BAUMAX']\n",
    "    print('Removed Columns are:', removed_columns)\n",
    "    df = df.drop(removed_columns,axis=1)\n",
    "    df[\"NAN count\"] = df.isna().sum(axis=1)\n",
    "    df = df.loc[df[\"NAN count\"] < upper_bound_row]\n",
    "    df = df.drop(columns=[\"NAN count\"])\n",
    "    df = fill_missing_values(df)\n",
    "    # select, re-encode, and engineer column values.\n",
    "    df = df.drop(columns = ['GEBAEUDETYP'])\n",
    "    categorical = feat_info[feat_info['type'] == 'categorical'].attribute\n",
    "    categorical = categorical.apply(lambda x: x if x in df.columns else np.NAN).dropna()\n",
    "    categorical_levels = {'binary-level':[], 'binary-level-re-encoded':[],'multi-level-re-encoded':[]}\n",
    "    for categorical_col in categorical:\n",
    "        unique_categories = pd.Series(df[categorical_col].unique()).dropna().to_list()\n",
    "        if len(unique_categories) == 2:\n",
    "            if str(unique_categories[0]).isalpha() or str(unique_categories[1]).isalpha():\n",
    "                categorical_levels['binary-level-re-encoded'].append(categorical_col)\n",
    "            else:\n",
    "                categorical_levels['binary-level'].append(categorical_col)\n",
    "        elif len(unique_categories) > 2:\n",
    "            categorical_levels['multi-level-re-encoded'].append(categorical_col)\n",
    "    for categorical_col in categorical_levels['multi-level-re-encoded']:\n",
    "        df.loc[:, categorical_col] = df[categorical_col].apply(lambda x: x if str(x).isalpha() else str(x))\n",
    "    df[categorical_levels['binary-level-re-encoded'][0]] = df[categorical_levels['binary-level-re-encoded'][0]].apply(lambda x: 0 if x == 'W' else 1)\n",
    "    multiple_dummy_attributes = pd.get_dummies(df[categorical_levels['multi-level-re-encoded']])\n",
    "    df = pd.concat([df, multiple_dummy_attributes],axis=1)\n",
    "    df = df.drop(categorical_levels['multi-level-re-encoded'],axis='columns')\n",
    "    # Create first variable movement wiht two bianry values: 0 for avantgarde and 1 for mainstream\n",
    "    df['movement'] = df['PRAEGENDE_JUGENDJAHRE'].apply(movement_encoding)\n",
    "    # Create second variable decade with multi-values: 0 for 40s and 1 for 50s and 2 for 60s \n",
    "    # and 3 for 70s and 4 for 80s and 5 for 90s\n",
    "    df['decade'] = df['PRAEGENDE_JUGENDJAHRE'].apply(decade_encoding)\n",
    "    # Create first variable wealth with multi-values: 0 for (11,12,13,14,15) and 1 for (21,22,23,24,25) and 2 for (31,32,33,34,35)\n",
    "    # and 3 for (41,42,43,44,45) and 4 for (51,52,53,54,55)\n",
    "    df[\"CAMEO_INTL_2015\"]= df[\"CAMEO_INTL_2015\"].astype(float)\n",
    "    df['wealth'] = df['CAMEO_INTL_2015'].apply(wealth_encoding)\n",
    "    # create second variable life_stage with multi-values: 0 for (11,21,31,41,51) and 1 for (12,22,32,42,52)\n",
    "    # and 2 for (13,23,33,43,53) and 3 for (14,24,34,44,54) and 4 for (15,25,35,45,55)\n",
    "    df['life_stage'] = df['CAMEO_INTL_2015'].apply(life_stage_encoding)\n",
    "    df = df.drop([\"PRAEGENDE_JUGENDJAHRE\", \"CAMEO_INTL_2015\"], axis= 1)\n",
    "    # Return the cleaned dataframe.\n",
    "    df = df.drop(columns=['LP_LEBENSPHASE_FEIN', 'LP_LEBENSPHASE_GROB'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
