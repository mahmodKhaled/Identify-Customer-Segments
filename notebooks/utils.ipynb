{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Encoding class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataEncoder():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def movement_encoding(self, x):\n",
    "        \"\"\"\n",
    "        Encodes an input value into a binary value for movement.\n",
    "        \n",
    "        Parameters:\n",
    "        x (int): The input value to be encoded.\n",
    "        \n",
    "        Returns:\n",
    "        int: The encoded binary value. 0 for mainstream, 1 for avantgrade.\n",
    "        if x not in any of the above return x \n",
    "        \n",
    "        \"\"\"\n",
    "        mainstream_codes = [1, 3, 5, 8, 10, 12, 14]\n",
    "        avantgrade_codes = [2, 4, 6, 7, 9, 11, 13, 15]\n",
    "        if x in mainstream_codes:\n",
    "            x = 0\n",
    "        elif x in avantgrade_codes:\n",
    "            x = 1\n",
    "        else:\n",
    "            x = x\n",
    "        return x\n",
    "\n",
    "    def decade_encoding(self, x):\n",
    "        \"\"\"\n",
    "        Encodes an input value into a discrete value for decade.\n",
    "        \n",
    "        Parameters:\n",
    "        x (int): The input value to be encoded.\n",
    "        \n",
    "        Returns:\n",
    "        int: The encoded discrete value representing a decade.\n",
    "        if x = 1 or 2 return 0 (40s)\n",
    "        if x = 3 or 4 return 1 (50s)\n",
    "        if x = 5 or 6 or 7 return 2 (60s)\n",
    "        if x = 8 or 9 return 3 (70s)\n",
    "        if x = 10 or 11 or 12 return 4 (80s)\n",
    "        if x = 13 or 14 or 15 return 5 (90s)\n",
    "        if x not in any of the above return x \n",
    "        \n",
    "        \"\"\"\n",
    "        decade_40s = [1, 2]\n",
    "        decade_50s = [3, 4]\n",
    "        decade_60s = [5, 6, 7]\n",
    "        decade_70s = [8, 9]\n",
    "        decade_80s = [10, 11, 12]\n",
    "        decade_90s = [13, 14, 15]\n",
    "        if x in decade_40s:\n",
    "            x = 0\n",
    "        elif x in decade_50s:\n",
    "            x = 1\n",
    "        elif x in decade_60s:\n",
    "            x = 2\n",
    "        elif x in decade_70s:\n",
    "            x = 3\n",
    "        elif x in decade_80s:\n",
    "            x = 4\n",
    "        elif x in decade_90s:\n",
    "            x = 5\n",
    "        else:\n",
    "            x = x \n",
    "        return x\n",
    "\n",
    "    def wealth_encoding(self, x):\n",
    "        \"\"\"\n",
    "        Encodes an input value into a discrete value for wealth.\n",
    "        \n",
    "        Parameters:\n",
    "        x (int): The input value to be encoded.\n",
    "        \n",
    "        Returns:\n",
    "        int: The encoded discrete value representing a wealth.\n",
    "        if x in wealthy_households return 0\n",
    "        if x in prosperous_households return 1\n",
    "        if x in comfortable_households return 2\n",
    "        if x in less_affluent_households return 3\n",
    "        if x in poorer_households return 4\n",
    "        if x not in any of the above return x \n",
    "        \n",
    "        \"\"\"\n",
    "        wealthy_households = [11,12,13,14,15]\n",
    "        prosperous_households = [21,22,23,24,25]\n",
    "        comfortable_households = [31,32,33,34,35]\n",
    "        less_affluent_households = [41,42,43,44,45]\n",
    "        poorer_households = [51,52,53,54,55]\n",
    "        if x in wealthy_households:\n",
    "            x = 0\n",
    "        elif x in prosperous_households:\n",
    "            x = 1\n",
    "        elif x in comfortable_households:\n",
    "            x = 2\n",
    "        elif x in less_affluent_households:\n",
    "            x = 3\n",
    "        elif x in poorer_households:\n",
    "            x = 4\n",
    "        else:\n",
    "            x = x\n",
    "        return x\n",
    "\n",
    "    def life_stage_encoding(self, x):\n",
    "        \"\"\"\n",
    "        Encodes an input value into a discrete value for life stage.\n",
    "        \n",
    "        Parameters:\n",
    "        x (int): The input value to be encoded.\n",
    "        \n",
    "        Returns:\n",
    "        int: The encoded discrete value representing a life stage.\n",
    "        if x in pre_family_couples_and_singles return 0\n",
    "        if x in young_couples_with_children return 1\n",
    "        if x in families_with_school_age_children return 2\n",
    "        if x in older_families_and_mature_couples return 3\n",
    "        if x in elders_in_retirement return 4\n",
    "        if x not in any of the above return x \n",
    "        \n",
    "        \"\"\"\n",
    "        pre_family_couples_and_singles = [11,21,31,41,51]\n",
    "        young_couples_with_children = [12,22,32,42,52]\n",
    "        families_with_school_age_children = [13,23,33,43,53]\n",
    "        older_families_and_mature_couples = [14,24,34,44,54]\n",
    "        elders_in_retirement = [15,25,35,45,55]\n",
    "        if x in pre_family_couples_and_singles:\n",
    "            x = 0\n",
    "        elif x in young_couples_with_children:\n",
    "            x = 1\n",
    "        elif x in families_with_school_age_children:\n",
    "            x = 2\n",
    "        elif x in older_families_and_mature_couples:\n",
    "            x = 3\n",
    "        elif x in elders_in_retirement:\n",
    "            x = 4\n",
    "        else:\n",
    "            x = x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MissingValuesImputer():\n",
    "    def __init__(self):\n",
    "        # initialize different imputers\n",
    "        self.categorical_mixed_imputer = SimpleImputer(missing_values= np.NAN, strategy= \"most_frequent\")\n",
    "        self.numerical_imputer = SimpleImputer(missing_values= np.NAN, strategy= \"mean\")\n",
    "        self.ordinal_imputer = SimpleImputer(missing_values= np.NAN, strategy= \"median\")\n",
    "    \n",
    "    def general_data_imputer(self, df, feat_info):\n",
    "        \"\"\"\n",
    "        This function imputes missing values in a DataFrame. It imputes different data types differently.\n",
    "        For categorical and mixed type columns, it uses the 'most_frequent' strategy.\n",
    "        For numerical type columns, it uses the 'mean' strategy.\n",
    "        For ordinal type columns, it uses the 'median' strategy.\n",
    "        \n",
    "        Parameters:\n",
    "        df (pandas.DataFrame): The DataFrame which has missing values to be imputed.\n",
    "        feat_info (pandas.DataFrame): The DataFrame which has information about the features.\n",
    "        \n",
    "        Returns:\n",
    "        df (pandas.DataFrame): The DataFrame with imputed missing values.\n",
    "        \n",
    "        \"\"\"\n",
    "        # impute categorical and mixed data types features\n",
    "        categorical_mixed_cols = feat_info[(feat_info['type'] == 'categorical') | (feat_info['type'] == 'mixed')].attribute\n",
    "        categorical_mixed_cols = categorical_mixed_cols.apply(lambda x: x if x in df.columns else np.NAN).dropna().to_list()\n",
    "        self.categorical_mixed_imputer.fit(df[categorical_mixed_cols])\n",
    "        imputed_categorical_mixed_columns = self.categorical_mixed_imputer.transform(df[categorical_mixed_cols])\n",
    "        imputed_categorical_mixed_columns = pd.DataFrame(imputed_categorical_mixed_columns, index= df.index, columns= categorical_mixed_cols)\n",
    "        df = df.drop(columns=categorical_mixed_cols)\n",
    "        df = pd.concat([df, imputed_categorical_mixed_columns], axis=1)\n",
    "        # impute numerical data types features\n",
    "        numerical_cols = feat_info[feat_info['type'] == 'numeric'].attribute\n",
    "        numerical_cols = numerical_cols.apply(lambda x: x if x in df.columns else np.NAN).dropna().to_list()\n",
    "        self.numerical_imputer.fit(df[numerical_cols])\n",
    "        imputed_numerical_columns = self.numerical_imputer.transform(df[numerical_cols])\n",
    "        imputed_numerical_columns = pd.DataFrame(imputed_numerical_columns, index= df.index, columns= numerical_cols)\n",
    "        df = df.drop(columns=numerical_cols)\n",
    "        df = pd.concat([df, imputed_numerical_columns], axis=1)\n",
    "        # impute ordinal data types features\n",
    "        ordinal_cols = feat_info[feat_info['type'] == 'ordinal'].attribute\n",
    "        ordinal_cols = ordinal_cols.apply(lambda x: x if x in df.columns else np.NAN).dropna().to_list()\n",
    "        self.ordinal_imputer.fit(df[ordinal_cols])\n",
    "        imputed_ordinal_columns = self.ordinal_imputer.transform(df[ordinal_cols])\n",
    "        imputed_ordinal_columns = pd.DataFrame(imputed_ordinal_columns, index= df.index, columns= ordinal_cols)\n",
    "        df = df.drop(columns=ordinal_cols)\n",
    "        df = pd.concat([df, imputed_ordinal_columns], axis=1)\n",
    "        return df\n",
    "    \n",
    "    def customer_data_imputer(self, df, feat_info):\n",
    "        \"\"\"\n",
    "        This function imputes missing values in a DataFrame. It imputes different data types differently.\n",
    "        For categorical and mixed type columns, it uses the 'most_frequent' strategy.\n",
    "        For numerical type columns, it uses the 'mean' strategy.\n",
    "        For ordinal type columns, it uses the 'median' strategy.\n",
    "        \n",
    "        Parameters:\n",
    "        df (pandas.DataFrame): The DataFrame which has missing values to be imputed.\n",
    "        feat_info (pandas.DataFrame): The DataFrame which has information about the features.\n",
    "        \n",
    "        Returns:\n",
    "        df (pandas.DataFrame): The DataFrame with imputed missing values.\n",
    "        \n",
    "        \"\"\"\n",
    "        # impute categorical and mixed data types features\n",
    "        categorical_mixed_cols = feat_info[(feat_info['type'] == 'categorical') | (feat_info['type'] == 'mixed')].attribute\n",
    "        categorical_mixed_cols = categorical_mixed_cols.apply(lambda x: x if x in df.columns else np.NAN).dropna().to_list()\n",
    "        imputed_categorical_mixed_columns = self.categorical_mixed_imputer.transform(df[categorical_mixed_cols])\n",
    "        imputed_categorical_mixed_columns = pd.DataFrame(imputed_categorical_mixed_columns, index= df.index, columns= categorical_mixed_cols)\n",
    "        df = df.drop(columns=categorical_mixed_cols)\n",
    "        df = pd.concat([df, imputed_categorical_mixed_columns], axis=1)\n",
    "        # impute numerical data types features\n",
    "        numerical_cols = feat_info[feat_info['type'] == 'numeric'].attribute\n",
    "        numerical_cols = numerical_cols.apply(lambda x: x if x in df.columns else np.NAN).dropna().to_list()\n",
    "        imputed_numerical_columns = self.numerical_imputer.transform(df[numerical_cols])\n",
    "        imputed_numerical_columns = pd.DataFrame(imputed_numerical_columns, index= df.index, columns= numerical_cols)\n",
    "        df = df.drop(columns=numerical_cols)\n",
    "        df = pd.concat([df, imputed_numerical_columns], axis=1)\n",
    "        # impute ordinal data types features\n",
    "        ordinal_cols = feat_info[feat_info['type'] == 'ordinal'].attribute\n",
    "        ordinal_cols = ordinal_cols.apply(lambda x: x if x in df.columns else np.NAN).dropna().to_list()\n",
    "        imputed_ordinal_columns = self.ordinal_imputer.transform(df[ordinal_cols])\n",
    "        imputed_ordinal_columns = pd.DataFrame(imputed_ordinal_columns, index= df.index, columns= ordinal_cols)\n",
    "        df = df.drop(columns=ordinal_cols)\n",
    "        df = pd.concat([df, imputed_ordinal_columns], axis=1)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCleaner():\n",
    "    def __init__(self):\n",
    "        self.upper_bound_row = 8\n",
    "\n",
    "    def clean_general_data(self, df, feat_info):\n",
    "        \"\"\"\n",
    "        Perform feature trimming, re-encoding, and engineering for demographics\n",
    "        data\n",
    "        \n",
    "        INPUT: Demographics DataFrame\n",
    "        OUTPUT: Trimmed and cleaned demographics DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        # Put in code here to execute all main cleaning steps:\n",
    "        # convert missing value codes into NaNs, ...\n",
    "        missing_values_codes = []\n",
    "        columns = []\n",
    "        for column, missing_value_code in zip(feat_info[\"attribute\"],feat_info[\"missing_or_unknown\"]):\n",
    "            missing_values_codes.extend(missing_value_code)\n",
    "            columns.extend([column] * len(missing_value_code))\n",
    "        for attribute , code in zip(columns, missing_values_codes):\n",
    "            df[attribute] = df[attribute].apply(lambda x: np.NAN if x == code else x)\n",
    "        # remove selected columns and rows, ...\n",
    "        removed_columns = ['AGER_TYP', 'GEBURTSJAHR', 'TITEL_KZ', 'ALTER_HH', 'KK_KUNDENTYP', 'KBA05_BAUMAX']\n",
    "        print('Removed Columns are:', removed_columns)\n",
    "        df = df.drop(removed_columns,axis=1)\n",
    "        df[\"NAN count\"] = df.isna().sum(axis=1)\n",
    "        df = df.loc[df[\"NAN count\"] < self.upper_bound_row]\n",
    "        df = df.drop(columns=[\"NAN count\"])\n",
    "        imputer = MissingValuesImputer()\n",
    "        df = imputer.general_data_imputer(df, feat_info)\n",
    "        # select, re-encode, and engineer column values.\n",
    "        df = df.drop(columns = ['GEBAEUDETYP'])\n",
    "        categorical = feat_info[feat_info['type'] == 'categorical'].attribute\n",
    "        categorical = categorical.apply(lambda x: x if x in df.columns else np.NAN).dropna()\n",
    "        categorical_levels = {'binary-level':[], 'binary-level-re-encoded':[],'multi-level-re-encoded':[]}\n",
    "        for categorical_col in categorical:\n",
    "            unique_categories = pd.Series(df[categorical_col].unique()).dropna().to_list()\n",
    "            if len(unique_categories) == 2:\n",
    "                if str(unique_categories[0]).isalpha() or str(unique_categories[1]).isalpha():\n",
    "                    categorical_levels['binary-level-re-encoded'].append(categorical_col)\n",
    "                else:\n",
    "                    categorical_levels['binary-level'].append(categorical_col)\n",
    "            elif len(unique_categories) > 2:\n",
    "                categorical_levels['multi-level-re-encoded'].append(categorical_col)\n",
    "        for categorical_col in categorical_levels['multi-level-re-encoded']:\n",
    "            df.loc[:, categorical_col] = df[categorical_col].apply(lambda x: x if str(x).isalpha() else str(x))\n",
    "        df[categorical_levels['binary-level-re-encoded'][0]] = df[categorical_levels['binary-level-re-encoded'][0]].apply(lambda x: 0 if x == 'W' else 1)\n",
    "        multiple_dummy_attributes = pd.get_dummies(df[categorical_levels['multi-level-re-encoded']])\n",
    "        df = pd.concat([df, multiple_dummy_attributes],axis=1)\n",
    "        df = df.drop(categorical_levels['multi-level-re-encoded'],axis='columns')\n",
    "        encoder = DataEncoder()\n",
    "        # Create first variable movement wiht two bianry values: 0 for avantgarde and 1 for mainstream\n",
    "        df['movement'] = df['PRAEGENDE_JUGENDJAHRE'].apply(encoder.movement_encoding)\n",
    "        # Create second variable decade with multi-values: 0 for 40s and 1 for 50s and 2 for 60s \n",
    "        # and 3 for 70s and 4 for 80s and 5 for 90s\n",
    "        df['decade'] = df['PRAEGENDE_JUGENDJAHRE'].apply(encoder.decade_encoding)\n",
    "        # Create first variable wealth with multi-values: 0 for (11,12,13,14,15) and 1 for (21,22,23,24,25) and 2 for (31,32,33,34,35)\n",
    "        # and 3 for (41,42,43,44,45) and 4 for (51,52,53,54,55)\n",
    "        df[\"CAMEO_INTL_2015\"]= df[\"CAMEO_INTL_2015\"].astype(float)\n",
    "        df['wealth'] = df['CAMEO_INTL_2015'].apply(encoder.wealth_encoding)\n",
    "        # create second variable life_stage with multi-values: 0 for (11,21,31,41,51) and 1 for (12,22,32,42,52)\n",
    "        # and 2 for (13,23,33,43,53) and 3 for (14,24,34,44,54) and 4 for (15,25,35,45,55)\n",
    "        df['life_stage'] = df['CAMEO_INTL_2015'].apply(encoder.life_stage_encoding)\n",
    "        df = df.drop([\"PRAEGENDE_JUGENDJAHRE\", \"CAMEO_INTL_2015\"], axis= 1)\n",
    "        # Return the cleaned dataframe.\n",
    "        df = df.drop(columns=['LP_LEBENSPHASE_FEIN', 'LP_LEBENSPHASE_GROB'])\n",
    "        return df\n",
    "    \n",
    "    def clean_customer_data(self, df, feat_info):\n",
    "        \"\"\"\n",
    "        Perform feature trimming, re-encoding, and engineering for demographics\n",
    "        data\n",
    "        \n",
    "        INPUT: Demographics DataFrame\n",
    "        OUTPUT: Trimmed and cleaned demographics DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        # Put in code here to execute all main cleaning steps:\n",
    "        # convert missing value codes into NaNs, ...\n",
    "        missing_values_codes = []\n",
    "        columns = []\n",
    "        for column, missing_value_code in zip(feat_info[\"attribute\"],feat_info[\"missing_or_unknown\"]):\n",
    "            missing_values_codes.extend(missing_value_code)\n",
    "            columns.extend([column] * len(missing_value_code))\n",
    "        for attribute , code in zip(columns, missing_values_codes):\n",
    "            df[attribute] = df[attribute].apply(lambda x: np.NAN if x == code else x)\n",
    "        # remove selected columns and rows, ...\n",
    "        removed_columns = ['AGER_TYP', 'GEBURTSJAHR', 'TITEL_KZ', 'ALTER_HH', 'KK_KUNDENTYP', 'KBA05_BAUMAX']\n",
    "        print('Removed Columns are:', removed_columns)\n",
    "        df = df.drop(removed_columns,axis=1)\n",
    "        df[\"NAN count\"] = df.isna().sum(axis=1)\n",
    "        df = df.loc[df[\"NAN count\"] < upper_bound_row]\n",
    "        df = df.drop(columns=[\"NAN count\"])\n",
    "        imputer = MissingValuesImputer()\n",
    "        df = imputer.customer_data_imputer(df, feat_info)\n",
    "        # select, re-encode, and engineer column values.\n",
    "        df = df.drop(columns = ['GEBAEUDETYP'])\n",
    "        categorical = feat_info[feat_info['type'] == 'categorical'].attribute\n",
    "        categorical = categorical.apply(lambda x: x if x in df.columns else np.NAN).dropna()\n",
    "        categorical_levels = {'binary-level':[], 'binary-level-re-encoded':[],'multi-level-re-encoded':[]}\n",
    "        for categorical_col in categorical:\n",
    "            unique_categories = pd.Series(df[categorical_col].unique()).dropna().to_list()\n",
    "            if len(unique_categories) == 2:\n",
    "                if str(unique_categories[0]).isalpha() or str(unique_categories[1]).isalpha():\n",
    "                    categorical_levels['binary-level-re-encoded'].append(categorical_col)\n",
    "                else:\n",
    "                    categorical_levels['binary-level'].append(categorical_col)\n",
    "            elif len(unique_categories) > 2:\n",
    "                categorical_levels['multi-level-re-encoded'].append(categorical_col)\n",
    "        for categorical_col in categorical_levels['multi-level-re-encoded']:\n",
    "            df.loc[:, categorical_col] = df[categorical_col].apply(lambda x: x if str(x).isalpha() else str(x))\n",
    "        df[categorical_levels['binary-level-re-encoded'][0]] = df[categorical_levels['binary-level-re-encoded'][0]].apply(lambda x: 0 if x == 'W' else 1)\n",
    "        multiple_dummy_attributes = pd.get_dummies(df[categorical_levels['multi-level-re-encoded']])\n",
    "        df = pd.concat([df, multiple_dummy_attributes],axis=1)\n",
    "        df = df.drop(categorical_levels['multi-level-re-encoded'],axis='columns')\n",
    "        encoder = DataEncoder()\n",
    "        # Create first variable movement wiht two bianry values: 0 for avantgarde and 1 for mainstream\n",
    "        df['movement'] = df['PRAEGENDE_JUGENDJAHRE'].apply(encoder.movement_encoding)\n",
    "        # Create second variable decade with multi-values: 0 for 40s and 1 for 50s and 2 for 60s \n",
    "        # and 3 for 70s and 4 for 80s and 5 for 90s\n",
    "        df['decade'] = df['PRAEGENDE_JUGENDJAHRE'].apply(encoder.decade_encoding)\n",
    "        # Create first variable wealth with multi-values: 0 for (11,12,13,14,15) and 1 for (21,22,23,24,25) and 2 for (31,32,33,34,35)\n",
    "        # and 3 for (41,42,43,44,45) and 4 for (51,52,53,54,55)\n",
    "        df[\"CAMEO_INTL_2015\"]= df[\"CAMEO_INTL_2015\"].astype(float)\n",
    "        df['wealth'] = df['CAMEO_INTL_2015'].apply(encoder.wealth_encoding)\n",
    "        # create second variable life_stage with multi-values: 0 for (11,21,31,41,51) and 1 for (12,22,32,42,52)\n",
    "        # and 2 for (13,23,33,43,53) and 3 for (14,24,34,44,54) and 4 for (15,25,35,45,55)\n",
    "        df['life_stage'] = df['CAMEO_INTL_2015'].apply(encoder.life_stage_encoding)\n",
    "        df = df.drop([\"PRAEGENDE_JUGENDJAHRE\", \"CAMEO_INTL_2015\"], axis= 1)\n",
    "        # Return the cleaned dataframe.\n",
    "        df = df.drop(columns=['LP_LEBENSPHASE_FEIN', 'LP_LEBENSPHASE_GROB'])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Count Visualizer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCountVisualizer():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def count_plot(self, data1, data2, column_name, super_title, sub_title1, sub_title2):\n",
    "        \"\"\"\n",
    "        This function creates a countplot of a column of data in two different data sets.\n",
    "\n",
    "        Parameters:\n",
    "        data1 (pandas dataframe): The first data set to be plotted.\n",
    "        data2 (pandas dataframe): The second data set to be plotted.\n",
    "        column_name (str): The name of the column to be plotted.\n",
    "        super_title (str): The title of the entire plot.\n",
    "        sub_title1 (str): The title of the first subplot.\n",
    "        sub_title2 (str): The title of the second subplot.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        figure , ax = plt.subplots(1,2)\n",
    "        figure.suptitle(super_title)\n",
    "        figure.set_figheight(7)\n",
    "        figure.set_figwidth(18)\n",
    "        sns.countplot(x=column_name, data=data1, ax=ax[0])\n",
    "        ax[0].set_title(sub_title1)\n",
    "        sns.countplot(x=column_name, data=data2, ax=ax[1])\n",
    "        ax[1].set_title(sub_title2)\n",
    "    \n",
    "    def proportion_plot(self, data1, data2, column_name, super_title, sub_title1, sub_title2):\n",
    "        \"\"\"\n",
    "        This function creates a countplot of a column of data in two different data sets. \n",
    "\n",
    "        Parameters:\n",
    "        data1 (pandas dataframe): The first data set to be plotted.\n",
    "        data2 (pandas dataframe): The second data set to be plotted.\n",
    "        column_name (str): The name of the column to be plotted.\n",
    "        super_title (str): The title of the entire plot.\n",
    "        sub_title1 (str): The title of the first subplot.\n",
    "        sub_title2 (str): The title of the second subplot.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        figure , ax = plt.subplots(1,2)\n",
    "        figure.suptitle(super_title)\n",
    "        figure.set_figheight(7)\n",
    "        figure.set_figwidth(18)\n",
    "        proportions_1 = data1[column_name].value_counts(normalize=True)\n",
    "        proportions_2 = data2[column_name].value_counts(normalize=True)\n",
    "        sns.barplot(x=proportions_1.index, y=proportions_1.values, ax=ax[0])\n",
    "        ax[0].set_title(sub_title1)\n",
    "        sns.barplot(x=proportions_2.index, y=proportions_2.values, ax=ax[1])\n",
    "        ax[1].set_title(sub_title2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
